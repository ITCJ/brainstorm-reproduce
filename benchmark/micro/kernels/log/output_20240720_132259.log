Get devices for measurement successfully!
#### # Linerar 192 4096 16384
/root/siton-data-guoguodata/tcj/brainstorm_project/brainstorm/.cache/log/kernel_tune/NVIDIA_A800_80GB_PCIe/Linear_forward_input_0_192_4096_output_0_192_16384_in_features_4096_out_features_16384.json
/root/siton-data-guoguodata/tcj/brainstorm_project/brainstorm/.cache/log/kernel_tune/NVIDIA_A800_80GB_PCIe/Linear_forward_input_0_192_4096_output_0_192_16384_in_features_4096_out_features_16384.json
#### Find tuned kernel, pass
type(x)<class 'list'>
type(y)<class 'list'>
type(linear.weight)<class 'torch.nn.parameter.Parameter'>
------------make_jit_kernel@factory.py-----------------
objective_func:fastest
-----------------make_kernel@ModuleBase---------------------
---------_make_global_kernel@LinearModule-----------
sample_inputs.shape:torch.Size([192, 4096])
self.module_name:Linear
method:forward
input_infos:{'input_0': [192, 4096]}
output_infos:{'output_0': [192, 16384]}
parameters:{'in_features': 4096, 'out_features': 16384}
objective_func:fastest
-------load_from_db@ModuleKernel--------
identifier:{"device_name": "NVIDIA_A800_80GB_PCIe", "input_infos": {"input_0": [192, 4096]}, "method": "forward", "op_type": "Linear", "output_infos": {"output_0": [192, 16384]}, "parameters": {"in_features": 4096, "out_features": 16384}}
objective_func:fastest
self.platform:CUDA_GPU
self.input_infos:{'input_0': [192, 4096]}
self.output_infos:{'output_0': [192, 16384]}
---------_make_global_kernel@LinearModule-----------
sample_inputs.shape:torch.Size([192, 4096])
self.module_name:Linear
method:forward
input_infos:{'input_0': [192, 4096]}
output_infos:{'output_0': [192, 16384]}
parameters:{'in_features': 4096, 'out_features': 16384}
objective_func:fastest
-------load_from_db@ModuleKernel--------
identifier:{"device_name": "NVIDIA_A800_80GB_PCIe", "input_infos": {"input_0": [192, 4096]}, "method": "forward", "op_type": "Linear", "output_infos": {"output_0": [192, 16384]}, "parameters": {"in_features": 4096, "out_features": 16384}}
objective_func:fastest
self.platform:CUDA_GPU
self.input_infos:{'input_0': [192, 4096]}
self.output_infos:{'output_0': [192, 16384]}
-----------init@HorizFusedKernel-------------
-------------initialize@HorizFusedKernel-------------
self.device_args['placeholder_0, placeholder1_0, T_matmul_NT_0', 'placeholder_1, placeholder1_1, T_matmul_NT_1']
self.shm_sizes[8192]
self.min_blocks_per_sm:1
self.blockidx_x:2048
-----------------get_code@GlobalKernel---------------------
--------------------------------------
processed_template_fname:/root/siton-data-guoguodata/tcj/brainstorm_project/brainstorm/.cache/kernel_template/processed_Linear__in.cu
-------------generate_kernel@CUDACompiler---------------
-------------global@CUDACompiler---------------
